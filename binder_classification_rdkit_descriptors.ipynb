{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8792a1ad",
   "metadata": {},
   "source": [
    "# Binder Classification â€” RDKit Descriptor Analysis\n",
    "\n",
    "This notebook isolates the RDKit descriptor workflow from `binder_classification_smiles.ipynb` so we can focus on descriptor-driven features, compare multiple classifiers, quantify their stability via stratified k-fold validation, and perform binary particle swarm optimization (BPSO) feature selection on the descriptor space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce5970",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b70017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault('OMP_NUM_THREADS', '1')\n",
    "os.environ.setdefault('RDKIT_MAX_THREADS', '1')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    auc,\n",
    "    matthews_corrcoef,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    "    average_precision_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab000b",
   "metadata": {},
   "source": [
    "## 2) Dataset Loading & Binder Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0876a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 25 compounds due to unwanted ion patterns\n",
      "Removed 787 duplicate SMILES entries\n",
      "Dataset size: 2039 compounds\n",
      "Binder ratio: 64.64%\n",
      "Sample SMILES:\n",
      "1. CN(C)OC(=O)CCC(=O)O | Binder: 0\n",
      "2. CC(=O)CC(=O)CCC(=O)O | Binder: 0\n",
      "3. Cc1cccc(C)c1Oc1cc2c(N3CCCC3)nc(-n3cc(C(=O)O)cn3)nc2cc1F | Binder: 1\n",
      "4. N#Cc1cccc(NC(=O)c2ccc3cccnc3c2O)c1 | Binder: 0\n",
      "5. COc1ccc(CNC(=O)c2ccc3cccnc3c2O)cc1 | Binder: 0\n"
     ]
    }
   ],
   "source": [
    "# Load curated IC50 dataset and define the binary binder label\n",
    "\n",
    "df_smiles = pd.read_csv(\"ic50.tsv\", sep=\"\t\", low_memory=False)\n",
    "df_smiles[\"Standard Value\"] = pd.to_numeric(df_smiles[\"Standard Value\"], errors=\"coerce\")\n",
    "\n",
    "df_smiles = df_smiles.dropna(subset=[\"Standard Value\", \"Smiles\"]).copy()\n",
    "df_smiles[\"Binder\"] = (df_smiles[\"Standard Value\"] <= 2000).astype(int)\n",
    "\n",
    "unwanted_patterns = [\n",
    "    \".C\", \".Cl\", \".NA+\", \".Na+\", \".na+\", \"[Na+]\", \"Cl.\", \".O=C(O)C(F)(F)F\"\n",
    "]\n",
    "mask = pd.Series(False, index=df_smiles.index)\n",
    "for pattern in unwanted_patterns:\n",
    "    mask |= df_smiles[\"Smiles\"].str.contains(pattern, regex=False, na=False)\n",
    "removed = int(mask.sum())\n",
    "if removed:\n",
    "    df_smiles = df_smiles[~mask].copy()\n",
    "    print(f\"Removed {removed} compounds due to unwanted ion patterns\")\n",
    "\n",
    "dupe_mask = df_smiles.duplicated(subset=\"Smiles\", keep=\"first\")\n",
    "removed_dupes = int(dupe_mask.sum())\n",
    "if removed_dupes:\n",
    "    df_smiles = df_smiles[~dupe_mask].copy()\n",
    "    print(f\"Removed {removed_dupes} duplicate SMILES entries\")\n",
    "\n",
    "print(f\"Dataset size: {len(df_smiles)} compounds\")\n",
    "print(f\"Binder ratio: {df_smiles['Binder'].mean()*100:.2f}%\")\n",
    "print(\"Sample SMILES:\")\n",
    "for i, (_, row) in enumerate(df_smiles.head(5).iterrows(), 1):\n",
    "    smiles_str = row['Smiles'][:70] + \"...\" if len(row['Smiles']) > 70 else row['Smiles']\n",
    "    print(f\"{i}. {smiles_str} | Binder: {row['Binder']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c215cb56",
   "metadata": {},
   "source": [
    "## 3) RDKit Descriptor Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e22586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating RDKit descriptors...\n",
      "Removed 1 descriptor(s) that exceeded float32 limits: ['Ipc']\n",
      "Descriptor matrix shape: (2039, 216)\n",
      "Total valid molecules: 2039\n"
     ]
    }
   ],
   "source": [
    "# Compute RDKit molecular descriptors and clean the resulting feature matrix\n",
    "\n",
    "descriptor_names = [name for name, _ in Descriptors._descList]\n",
    "descriptor_calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
    "\n",
    "def smiles_to_descriptors(smiles: str):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        return descriptor_calculator.CalcDescriptors(mol)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "print(\"Calculating RDKit descriptors...\")\n",
    "descriptor_rows = []\n",
    "descriptor_indices = []\n",
    "\n",
    "for idx, smiles in enumerate(df_smiles['Smiles']):\n",
    "    values = smiles_to_descriptors(smiles)\n",
    "    if values is not None:\n",
    "        descriptor_rows.append(values)\n",
    "        descriptor_indices.append(idx)\n",
    "\n",
    "descriptor_df = pd.DataFrame(descriptor_rows, columns=descriptor_names)\n",
    "descriptor_df = descriptor_df.replace([np.inf, -np.inf], np.nan)\n",
    "all_nan_cols = descriptor_df.columns[descriptor_df.isna().all()].tolist()\n",
    "if all_nan_cols:\n",
    "    descriptor_df = descriptor_df.drop(columns=all_nan_cols)\n",
    "descriptor_df = descriptor_df.fillna(descriptor_df.median())\n",
    "\n",
    "float32_limit = np.finfo(np.float32).max\n",
    "too_large_mask = descriptor_df.abs() >= float32_limit\n",
    "if too_large_mask.any().any():\n",
    "    bad_columns = descriptor_df.columns[too_large_mask.any(axis=0)].tolist()\n",
    "    descriptor_df = descriptor_df.drop(columns=bad_columns)\n",
    "    print(f\"Removed {len(bad_columns)} descriptor(s) that exceeded float32 limits: {bad_columns}\")\n",
    "\n",
    "descriptor_df = descriptor_df.astype(np.float64)\n",
    "\n",
    "X_desc = descriptor_df.values\n",
    "y_desc = df_smiles.iloc[descriptor_indices]['Binder'].values\n",
    "\n",
    "print(f\"Descriptor matrix shape: {descriptor_df.shape}\")\n",
    "print(f\"Total valid molecules: {len(descriptor_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1e77a",
   "metadata": {},
   "source": [
    "## 4) Baseline Random Forest Holdout Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fb6a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit descriptor Random Forest performance (holdout test set)\n",
      "PR-AUC: 0.98669\n",
      "ROC-AUC: 0.97449\n",
      "MCC: 0.84867\n",
      "Accuracy: 0.93137\n",
      "Balanced Accuracy: 0.91919\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9240    0.8778    0.9003       180\n",
      "           1     0.9351    0.9606    0.9477       330\n",
      "\n",
      "    accuracy                         0.9314       510\n",
      "   macro avg     0.9295    0.9192    0.9240       510\n",
      "weighted avg     0.9312    0.9314    0.9310       510\n",
      "\n",
      "Top descriptor importances (Random Forest)\n",
      "                     Importance\n",
      "AvgIpc                 0.038577\n",
      "MaxAbsPartialCharge    0.036648\n",
      "PEOE_VSA11             0.036358\n",
      "MinPartialCharge       0.035454\n",
      "BCUT2D_MRLOW           0.026597\n",
      "SMR_VSA3               0.025926\n",
      "fr_Ar_N                0.023560\n",
      "EState_VSA8            0.019652\n",
      "PEOE_VSA12             0.019053\n",
      "VSA_EState7            0.018084\n",
      "VSA_EState2            0.016334\n",
      "fr_NH0                 0.015760\n",
      "SlogP_VSA3             0.015250\n",
      "MinAbsPartialCharge    0.015054\n",
      "MaxPartialCharge       0.015021\n"
     ]
    }
   ],
   "source": [
    "X_train_desc, X_test_desc, y_train_desc, y_test_desc = train_test_split(\n",
    "    X_desc,\n",
    "    y_desc,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y_desc\n",
    ")\n",
    "\n",
    "desc_rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_depth=24,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "\n",
    "desc_rf.fit(X_train_desc, y_train_desc)\n",
    "\n",
    "y_desc_pred = desc_rf.predict(X_test_desc)\n",
    "y_desc_prob = desc_rf.predict_proba(X_test_desc)[:, 1]\n",
    "\n",
    "desc_precision, desc_recall, _ = precision_recall_curve(y_test_desc, y_desc_prob)\n",
    "desc_pr_auc = auc(desc_recall, desc_precision)\n",
    "desc_roc_auc = roc_auc_score(y_test_desc, y_desc_prob)\n",
    "desc_mcc = matthews_corrcoef(y_test_desc, y_desc_pred)\n",
    "desc_acc = accuracy_score(y_test_desc, y_desc_pred)\n",
    "desc_bal_acc = balanced_accuracy_score(y_test_desc, y_desc_pred)\n",
    "\n",
    "print(\"RDKit descriptor Random Forest performance (holdout test set)\")\n",
    "print(f\"PR-AUC: {desc_pr_auc:.5f}\")\n",
    "print(f\"ROC-AUC: {desc_roc_auc:.5f}\")\n",
    "print(f\"MCC: {desc_mcc:.5f}\")\n",
    "print(f\"Accuracy: {desc_acc:.5f}\")\n",
    "print(f\"Balanced Accuracy: {desc_bal_acc:.5f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test_desc, y_desc_pred, digits=4))\n",
    "\n",
    "descriptor_importances = pd.Series(desc_rf.feature_importances_, index=descriptor_df.columns)\n",
    "top_desc = descriptor_importances.sort_values(ascending=False).head(15)\n",
    "print(\"Top descriptor importances (Random Forest)\")\n",
    "print(top_desc.to_frame(name='Importance'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194cc407",
   "metadata": {},
   "source": [
    "## 5) Helper Functions for Stratified K-Fold Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f62164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities shared by every classifier evaluation\n",
    "\n",
    "def _positive_class_probs(model, X):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        raw = model.decision_function(X)\n",
    "        return 1.0 / (1.0 + np.exp(-raw))\n",
    "    # Last resort: fall back to hard predictions\n",
    "    return model.predict(X).astype(float)\n",
    "\n",
    "def _metric_summary(y_true, y_pred, y_prob):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    return {\n",
    "        \"PR_AUC\": auc(recall, precision),\n",
    "        \"ROC_AUC\": roc_auc_score(y_true, y_prob),\n",
    "        \"MCC\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "def run_stratified_kfold(model, X, y, n_splits=5, random_state=42):\n",
    "    splitter = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    fold_metrics = []\n",
    "    for train_idx, test_idx in splitter.split(X, y):\n",
    "        estimator = clone(model)\n",
    "        estimator.fit(X[train_idx], y[train_idx])\n",
    "        y_pred = estimator.predict(X[test_idx])\n",
    "        y_prob = _positive_class_probs(estimator, X[test_idx])\n",
    "        fold_metrics.append(_metric_summary(y[test_idx], y_pred, y_prob))\n",
    "    aggregated = {metric: np.mean([fold[metric] for fold in fold_metrics]) for metric in fold_metrics[0]}\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855971a3",
   "metadata": {},
   "source": [
    "## 6) Model Comparison with Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d6e8065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated descriptor model comparison\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Folds</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>5</td>\n",
       "      <td>0.979063</td>\n",
       "      <td>0.962775</td>\n",
       "      <td>0.793828</td>\n",
       "      <td>0.905346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>10</td>\n",
       "      <td>0.978519</td>\n",
       "      <td>0.963250</td>\n",
       "      <td>0.799978</td>\n",
       "      <td>0.908292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>5</td>\n",
       "      <td>0.922037</td>\n",
       "      <td>0.857921</td>\n",
       "      <td>0.588457</td>\n",
       "      <td>0.813163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>10</td>\n",
       "      <td>0.921846</td>\n",
       "      <td>0.856946</td>\n",
       "      <td>0.594422</td>\n",
       "      <td>0.815609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>5</td>\n",
       "      <td>0.983757</td>\n",
       "      <td>0.970325</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.909758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>10</td>\n",
       "      <td>0.983753</td>\n",
       "      <td>0.972582</td>\n",
       "      <td>0.814154</td>\n",
       "      <td>0.914660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5</td>\n",
       "      <td>0.969588</td>\n",
       "      <td>0.946579</td>\n",
       "      <td>0.752369</td>\n",
       "      <td>0.882789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971063</td>\n",
       "      <td>0.948861</td>\n",
       "      <td>0.761443</td>\n",
       "      <td>0.886709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.984241</td>\n",
       "      <td>0.971153</td>\n",
       "      <td>0.807324</td>\n",
       "      <td>0.911720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>10</td>\n",
       "      <td>0.984653</td>\n",
       "      <td>0.973391</td>\n",
       "      <td>0.812071</td>\n",
       "      <td>0.914182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Folds    PR_AUC   ROC_AUC       MCC  Accuracy\n",
       "0          ExtraTrees      5  0.979063  0.962775  0.793828  0.905346\n",
       "1          ExtraTrees     10  0.978519  0.963250  0.799978  0.908292\n",
       "2          GaussianNB      5  0.922037  0.857921  0.588457  0.813163\n",
       "3          GaussianNB     10  0.921846  0.856946  0.594422  0.815609\n",
       "4    GradientBoosting      5  0.983757  0.970325  0.803279  0.909758\n",
       "5    GradientBoosting     10  0.983753  0.972582  0.814154  0.914660\n",
       "6  LogisticRegression      5  0.969588  0.946579  0.752369  0.882789\n",
       "7  LogisticRegression     10  0.971063  0.948861  0.761443  0.886709\n",
       "8        RandomForest      5  0.984241  0.971153  0.807324  0.911720\n",
       "9        RandomForest     10  0.984653  0.973391  0.812071  0.914182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_registry = {\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=24,\n",
    "        min_samples_leaf=2\n",
    "    ),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(\n",
    "        n_estimators=500,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=400,\n",
    "        max_depth=3\n",
    "    ),\n",
    "    \"LogisticRegression\": make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(\n",
    "            penalty='elasticnet',\n",
    "            l1_ratio=0.4,\n",
    "            solver='saga',\n",
    "            max_iter=4000,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    ),\n",
    "    \"GaussianNB\": GaussianNB(var_smoothing=1e-9)\n",
    "}\n",
    "\n",
    "fold_options = (5, 10)\n",
    "cv_rows = []\n",
    "for model_name, estimator in model_registry.items():\n",
    "    for folds in fold_options:\n",
    "        metrics = run_stratified_kfold(estimator, X_desc, y_desc, n_splits=folds)\n",
    "        metrics.update({\"Model\": model_name, \"Folds\": folds})\n",
    "        cv_rows.append(metrics)\n",
    "\n",
    "cv_df = pd.DataFrame(cv_rows)\n",
    "cv_df = cv_df[[\"Model\", \"Folds\", \"PR_AUC\", \"ROC_AUC\", \"MCC\", \"Accuracy\"]]\n",
    "cv_df = cv_df.sort_values(by=[\"Model\", \"Folds\"]).reset_index(drop=True)\n",
    "print(\"Cross-validated descriptor model comparison\")\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03984d",
   "metadata": {},
   "source": [
    "## 7) BPSO Feature Selection on Descriptor Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec185afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BPSOFeatureSelector:\n",
    "    \"\"\"Binary Particle Swarm Optimization wrapper for descriptor feature selection.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        n_particles=20,\n",
    "        n_iterations=25,\n",
    "        inertia=0.729,\n",
    "        cognitive=1.49445,\n",
    "        social=1.49445,\n",
    "        cv=3,\n",
    "        max_features=256,\n",
    "        min_features=8,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        self.estimator = estimator\n",
    "        self.n_particles = n_particles\n",
    "        self.n_iterations = n_iterations\n",
    "        self.inertia = inertia\n",
    "        self.cognitive = cognitive\n",
    "        self.social = social\n",
    "        self.cv = cv\n",
    "        self.max_features = max_features\n",
    "        self.min_features = min_features\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _ensure_valid_mask(self, mask, rng):\n",
    "        if not mask.any():\n",
    "            mask[rng.integers(0, mask.size)] = True\n",
    "        if self.max_features is not None and mask.sum() > self.max_features:\n",
    "            drop = rng.choice(np.where(mask)[0], size=mask.sum() - self.max_features, replace=False)\n",
    "            mask[drop] = False\n",
    "        if self.min_features and mask.sum() < self.min_features:\n",
    "            available = np.where(~mask)[0]\n",
    "            if available.size:\n",
    "                add = rng.choice(available, size=min(self.min_features - mask.sum(), available.size), replace=False)\n",
    "                mask[add] = True\n",
    "        return mask\n",
    "\n",
    "    def _predict_scores(self, estimator, X):\n",
    "        if hasattr(estimator, \"predict_proba\"):\n",
    "            return estimator.predict_proba(X)[:, 1]\n",
    "        if hasattr(estimator, \"decision_function\"):\n",
    "            raw = estimator.decision_function(X)\n",
    "            return 1.0 / (1.0 + np.exp(-raw))\n",
    "        return estimator.predict(X)\n",
    "\n",
    "    def _evaluate_mask(self, X, y, mask):\n",
    "        if mask.sum() == 0:\n",
    "            return 0.0\n",
    "        scores = []\n",
    "        for train_idx, valid_idx in self.cv_splits_:\n",
    "            est = clone(self.estimator)\n",
    "            est.fit(X[train_idx][:, mask], y[train_idx])\n",
    "            y_scores = self._predict_scores(est, X[valid_idx][:, mask])\n",
    "            scores.append(average_precision_score(y[valid_idx], y_scores))\n",
    "        return float(np.mean(scores))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        self.cv_splits_ = list(\n",
    "            StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=self.random_state).split(X, y)\n",
    "        )\n",
    "        n_features = X.shape[1]\n",
    "        init_prob = min(0.1, (self.max_features or n_features) / n_features)\n",
    "        positions = rng.random((self.n_particles, n_features)) < init_prob\n",
    "        velocities = rng.standard_normal((self.n_particles, n_features)) * 0.1\n",
    "        for i in range(self.n_particles):\n",
    "            positions[i] = self._ensure_valid_mask(positions[i], rng)\n",
    "        personal_best_positions = positions.copy()\n",
    "        personal_best_scores = np.array([\n",
    "            self._evaluate_mask(X, y, positions[i]) for i in range(self.n_particles)\n",
    "        ])\n",
    "        best_idx = np.argmax(personal_best_scores)\n",
    "        global_best_position = personal_best_positions[best_idx].copy()\n",
    "        global_best_score = personal_best_scores[best_idx]\n",
    "        self.history_ = [\n",
    "            {\n",
    "                \"iteration\": 0,\n",
    "                \"best_score\": float(global_best_score),\n",
    "                \"mean_features\": float(positions.sum(axis=1).mean()),\n",
    "            }\n",
    "        ]\n",
    "        for iteration in range(1, self.n_iterations + 1):\n",
    "            for i in range(self.n_particles):\n",
    "                r1 = rng.random(n_features)\n",
    "                r2 = rng.random(n_features)\n",
    "                personal_best = personal_best_positions[i].astype(float)\n",
    "                position_float = positions[i].astype(float)\n",
    "                global_best = global_best_position.astype(float)\n",
    "                velocities[i] = (\n",
    "                    self.inertia * velocities[i]\n",
    "                    + self.cognitive * r1 * (personal_best - position_float)\n",
    "                    + self.social * r2 * (global_best - position_float)\n",
    "                )\n",
    "                probs = 1.0 / (1.0 + np.exp(-velocities[i]))\n",
    "                new_position = rng.random(n_features) < probs\n",
    "                new_position = self._ensure_valid_mask(new_position, rng)\n",
    "                positions[i] = new_position\n",
    "                score = self._evaluate_mask(X, y, new_position)\n",
    "                if score > personal_best_scores[i]:\n",
    "                    personal_best_scores[i] = score\n",
    "                    personal_best_positions[i] = new_position.copy()\n",
    "                    if score > global_best_score:\n",
    "                        global_best_score = score\n",
    "                        global_best_position = new_position.copy()\n",
    "            self.history_.append(\n",
    "                {\n",
    "                    \"iteration\": iteration,\n",
    "                    \"best_score\": float(global_best_score),\n",
    "                    \"mean_features\": float(positions.sum(axis=1).mean()),\n",
    "                }\n",
    "            )\n",
    "        self.support_ = global_best_position.astype(bool)\n",
    "        self.best_score_ = float(global_best_score)\n",
    "        self.selected_features_ = np.where(self.support_)[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not hasattr(self, \"support_\"):\n",
    "            raise RuntimeError(\"The selector is not fitted yet.\")\n",
    "        return np.asarray(X)[:, self.support_]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d411774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salmashahzad/Desktop/research me /.venv/lib/python3.14/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/salmashahzad/Desktop/research me /.venv/lib/python3.14/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/salmashahzad/Desktop/research me /.venv/lib/python3.14/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/salmashahzad/Desktop/research me /.venv/lib/python3.14/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/salmashahzad/Desktop/research me /.venv/lib/python3.14/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPSO selected 117 / 216 descriptors\n",
      "Best cross-validated average precision: 0.9718\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>best_score</th>\n",
       "      <th>mean_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.936339</td>\n",
       "      <td>21.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>124.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>123.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>117.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>117.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>117.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>116.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>116.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>117.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.971001</td>\n",
       "      <td>115.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.971001</td>\n",
       "      <td>115.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.971001</td>\n",
       "      <td>113.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.971001</td>\n",
       "      <td>111.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.971001</td>\n",
       "      <td>115.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>111.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>112.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>112.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>110.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>109.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>113.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>111.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>110.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>110.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>113.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>112.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.971750</td>\n",
       "      <td>113.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration  best_score  mean_features\n",
       "0           0    0.936339          21.70\n",
       "1           1    0.969327         124.10\n",
       "2           2    0.969327         123.55\n",
       "3           3    0.969327         117.10\n",
       "4           4    0.969327         117.35\n",
       "5           5    0.969327         117.70\n",
       "6           6    0.969327         116.05\n",
       "7           7    0.969327         116.60\n",
       "8           8    0.969327         117.10\n",
       "9           9    0.971001         115.75\n",
       "10         10    0.971001         115.25\n",
       "11         11    0.971001         113.55\n",
       "12         12    0.971001         111.45\n",
       "13         13    0.971001         115.90\n",
       "14         14    0.971750         111.80\n",
       "15         15    0.971750         112.10\n",
       "16         16    0.971750         112.70\n",
       "17         17    0.971750         110.60\n",
       "18         18    0.971750         109.45\n",
       "19         19    0.971750         113.40\n",
       "20         20    0.971750         111.35\n",
       "21         21    0.971750         110.60\n",
       "22         22    0.971750         110.80\n",
       "23         23    0.971750         113.35\n",
       "24         24    0.971750         112.65\n",
       "25         25    0.971750         113.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run BPSO on the training descriptors\n",
    "bpso_base_estimator = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(\n",
    "        max_iter=4000,\n",
    "        solver=\"saga\",\n",
    "        penalty=\"l2\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    ")\n",
    "\n",
    "bpso_selector = BPSOFeatureSelector(\n",
    "    estimator=bpso_base_estimator,\n",
    "    n_particles=20,\n",
    "    n_iterations=25,\n",
    "    cv=3,\n",
    "    max_features=256,\n",
    "    min_features=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "bpso_selector.fit(X_train_desc, y_train_desc)\n",
    "selected_desc_mask = bpso_selector.support_\n",
    "X_train_desc_bpso = X_train_desc[:, selected_desc_mask]\n",
    "X_test_desc_bpso = X_test_desc[:, selected_desc_mask]\n",
    "\n",
    "print(f\"BPSO selected {selected_desc_mask.sum()} / {X_train_desc.shape[1]} descriptors\")\n",
    "print(f\"Best cross-validated average precision: {bpso_selector.best_score_:.4f}\")\n",
    "\n",
    "bpso_desc_history = pd.DataFrame(bpso_selector.history_)\n",
    "try:\n",
    "    display(bpso_desc_history)\n",
    "except Exception as exc:\n",
    "    print(\"Display unavailable:\", exc)\n",
    "    print(bpso_desc_history.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19682cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Random Forest with BPSO-selected descriptors\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9162    0.8500    0.8818       180\n",
      "           1     0.9213    0.9576    0.9391       330\n",
      "\n",
      "    accuracy                         0.9196       510\n",
      "   macro avg     0.9187    0.9038    0.9105       510\n",
      "weighted avg     0.9195    0.9196    0.9189       510\n",
      "\n",
      "PR-AUC: 0.98555\n",
      "ROC-AUC: 0.97236\n",
      "MCC: 0.82238\n",
      "Accuracy: 0.91961\n",
      "Balanced Accuracy: 0.90379\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest on the BPSO-selected descriptors\n",
    "rf_desc_bpso = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_depth=24,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "rf_desc_bpso.fit(X_train_desc_bpso, y_train_desc)\n",
    "\n",
    "y_desc_bpso_pred = rf_desc_bpso.predict(X_test_desc_bpso)\n",
    "y_desc_bpso_prob = rf_desc_bpso.predict_proba(X_test_desc_bpso)[:, 1]\n",
    "\n",
    "precision_desc_bpso, recall_desc_bpso, _ = precision_recall_curve(y_test_desc, y_desc_bpso_prob)\n",
    "pr_auc_desc_bpso = auc(recall_desc_bpso, precision_desc_bpso)\n",
    "roc_auc_desc_bpso = roc_auc_score(y_test_desc, y_desc_bpso_prob)\n",
    "mcc_desc_bpso = matthews_corrcoef(y_test_desc, y_desc_bpso_pred)\n",
    "acc_desc_bpso = accuracy_score(y_test_desc, y_desc_bpso_pred)\n",
    "bal_acc_desc_bpso = balanced_accuracy_score(y_test_desc, y_desc_bpso_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Random Forest with BPSO-selected descriptors\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test_desc, y_desc_bpso_pred, digits=4))\n",
    "print(f\"PR-AUC: {pr_auc_desc_bpso:.5f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_desc_bpso:.5f}\")\n",
    "print(f\"MCC: {mcc_desc_bpso:.5f}\")\n",
    "print(f\"Accuracy: {acc_desc_bpso:.5f}\")\n",
    "print(f\"Balanced Accuracy: {bal_acc_desc_bpso:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64fe3496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full descriptor set vs BPSO-selected subset\n",
      "Styled display unavailable: The '.style' accessor requires jinja2\n",
      "                       Features Used  Selected Fraction (%)  PR-AUC  ROC-AUC  \\\n",
      "Model                                                                          \n",
      "RF + all descriptors             216                100.000   0.987    0.974   \n",
      "RF + BPSO descriptors            117                 54.167   0.986    0.972   \n",
      "\n",
      "                       Accuracy  Balanced Accuracy    MCC  \n",
      "Model                                                      \n",
      "RF + all descriptors      0.931              0.919  0.849  \n",
      "RF + BPSO descriptors     0.920              0.904  0.822  \n"
     ]
    }
   ],
   "source": [
    "comparison_rows = [\n",
    "    {\n",
    "        \"Model\": \"RF + all descriptors\",\n",
    "        \"Features Used\": X_train_desc.shape[1],\n",
    "        \"Selected Fraction (%)\": 100.0,\n",
    "        \"PR-AUC\": desc_pr_auc,\n",
    "        \"ROC-AUC\": desc_roc_auc,\n",
    "        \"Accuracy\": desc_acc,\n",
    "        \"Balanced Accuracy\": desc_bal_acc,\n",
    "        \"MCC\": desc_mcc,\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"RF + BPSO descriptors\",\n",
    "        \"Features Used\": int(selected_desc_mask.sum()),\n",
    "        \"Selected Fraction (%)\": selected_desc_mask.mean() * 100,\n",
    "        \"PR-AUC\": pr_auc_desc_bpso,\n",
    "        \"ROC-AUC\": roc_auc_desc_bpso,\n",
    "        \"Accuracy\": acc_desc_bpso,\n",
    "        \"Balanced Accuracy\": bal_acc_desc_bpso,\n",
    "        \"MCC\": mcc_desc_bpso,\n",
    "    },\n",
    "]\n",
    "comparison_desc_bpso_df = (\n",
    "    pd.DataFrame(comparison_rows)\n",
    "    .set_index(\"Model\")\n",
    "    .sort_values(\"PR-AUC\", ascending=False)\n",
    ")\n",
    "print(\"Full descriptor set vs BPSO-selected subset\")\n",
    "try:\n",
    "    display(\n",
    "        comparison_desc_bpso_df.style.format({\n",
    "            \"Features Used\": \"{:.0f}\",\n",
    "            \"Selected Fraction (%)\": \"{:.2f}\",\n",
    "            \"PR-AUC\": \"{:.3f}\",\n",
    "            \"ROC-AUC\": \"{:.3f}\",\n",
    "            \"Accuracy\": \"{:.3f}\",\n",
    "            \"Balanced Accuracy\": \"{:.3f}\",\n",
    "            \"MCC\": \"{:.3f}\",\n",
    "        })\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(\"Styled display unavailable:\", exc)\n",
    "    print(comparison_desc_bpso_df.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
