{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binder Classification — SMILES Fingerprint Feature Analysis\n",
    "\n",
    "This notebook contains the SMILES‑driven portion of the original workflow.\n",
    "We keep the same imports and helper utilities but focus exclusively on\n",
    "fingerprint generation, model training, and comparisons based on SMILES representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.metrics import (classification_report, precision_recall_curve, average_precision_score, roc_curve,\n",
    "                             auc, matthews_corrcoef, balanced_accuracy_score, accuracy_score, ConfusionMatrixDisplay)\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "\n",
    "# Plotting defaults: single-plot figures, no seaborn, no custom colors/styles\n",
    "plt.rcParams.update({\"figure.figsize\": (8,5), \"axes.grid\": True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 2) SMILES-Based Feature Analysis\n",
    "\n",
    "Now let's explore whether **SMILES strings** can be good features for binder prediction. We'll convert SMILES to molecular fingerprints and compare model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### 2.1) Check SMILES Data Quality\n",
    "\n",
    "> We also drop simple ionic SMILES patterns (e.g., Na+/Cl- fragments) before modeling to avoid duplicated mixture rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data for SMILES analysis\n",
    "df_smiles = pd.read_csv(\"ic50.tsv\", sep=\"\t\", low_memory=False)\n",
    "df_smiles[\"Standard Value\"] = pd.to_numeric(df_smiles[\"Standard Value\"], errors=\"coerce\")\n",
    "\n",
    "# Keep only rows with both SMILES and IC50\n",
    "df_smiles = df_smiles.dropna(subset=[\"Standard Value\", \"Smiles\"]).copy()\n",
    "df_smiles[\"Binder\"] = (df_smiles[\"Standard Value\"] <= 2000).astype(int)\n",
    "\n",
    "# Remove simple ions/mixtures that interfere with modeling\n",
    "unwanted_patterns = [\n",
    "    \".C\", \".Cl\", \".NA+\", \".Na+\", \".na+\", \"[Na+]\", \"Cl.\", \".O=C(O)C(F)(F)F\"\n",
    "]\n",
    "mask = pd.Series(False, index=df_smiles.index)\n",
    "for pattern in unwanted_patterns:\n",
    "    mask |= df_smiles[\"Smiles\"].str.contains(pattern, regex=False, na=False)\n",
    "removed = int(mask.sum())\n",
    "if removed:\n",
    "    df_smiles = df_smiles[~mask].copy()\n",
    "print(f\"Removed {removed} compounds due to unwanted ion patterns\")\n",
    "\n",
    "print(f\"Dataset size: {len(df_smiles)} compounds\")\n",
    "print(f\"SMILES coverage: {df_smiles['Smiles'].notna().sum()}/{len(df_smiles)} ({df_smiles['Smiles'].notna().mean()*100:.2f}%)\")\n",
    "\n",
    "print(f\"Class distribution with 2000 nM threshold:\")\n",
    "print(df_smiles[\"Binder\"].value_counts().sort_index())\n",
    "print(f\"Binder ratio: {df_smiles['Binder'].mean()*100:.2f}%\")\n",
    "print(f\"This is MUCH more balanced than the 2 nM threshold (~65% vs ~2-3%)\")\n",
    "\n",
    "# Show sample SMILES\n",
    "print(\"Sample SMILES strings:\")\n",
    "for i, (idx, row) in enumerate(df_smiles.head(5).iterrows(), 1):\n",
    "    smiles_str = row['Smiles'][:70] + \"...\" if len(row['Smiles']) > 70 else row['Smiles']\n",
    "    print(f\"{i}. {smiles_str} | Binder: {row['Binder']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### 2.2) Convert SMILES to Molecular Fingerprints\n",
    "\n",
    "We'll use **RDKit** to convert SMILES to Morgan fingerprints (circular fingerprints similar to ECFP). These capture molecular structure and are commonly used in cheminformatics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "import numpy as np\n",
    "\n",
    "def smiles_to_fingerprint(smiles, radius=2, n_bits=4096):\n",
    "    \"\"\"Convert SMILES to Morgan fingerprint using MorganGenerator.\n",
    "    \n",
    "    Default: 4096 bits (optimized for best performance)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        # Use the new MorganGenerator API (not deprecated)\n",
    "        morgan_gen = GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
    "        fp = morgan_gen.GetFingerprint(mol)\n",
    "        return np.array(fp)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Convert all SMILES to fingerprints\n",
    "print(\"Converting SMILES to fingerprints (4096 bits)...\")\n",
    "fingerprints = []\n",
    "valid_indices = []\n",
    "\n",
    "for idx, smiles in enumerate(df_smiles['Smiles']):\n",
    "    fp = smiles_to_fingerprint(smiles)\n",
    "    if fp is not None:\n",
    "        fingerprints.append(fp)\n",
    "        valid_indices.append(idx)\n",
    "\n",
    "# Create feature matrix\n",
    "X_fp = np.array(fingerprints)\n",
    "y_fp = df_smiles.iloc[valid_indices]['Binder'].values\n",
    "\n",
    "print(f\"Successfully converted {len(fingerprints)} out of {len(df_smiles)} SMILES\")\n",
    "print(f\"Fingerprint shape: {X_fp.shape}\")\n",
    "print(f\"Each compound represented by {X_fp.shape[1]} binary features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### 2.3) Train Model with SMILES Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_fp, X_test_fp, y_train_fp, y_test_fp = train_test_split(\n",
    "    X_fp, y_fp, test_size=0.25, random_state=42, stratify=y_fp\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_fp.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_fp.shape[0]} samples\")\n",
    "print(f\"Features: {X_train_fp.shape[1]} fingerprint bits\")\n",
    "\n",
    "# Train Random Forest with SMILES fingerprints (DEFAULT parameters)\n",
    "rf_smiles = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    # Using default max_depth=None for fair comparison\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest on SMILES fingerprints (default parameters)...\")\n",
    "rf_smiles.fit(X_train_fp, y_train_fp)\n",
    "\n",
    "# Predictions\n",
    "y_pred_fp = rf_smiles.predict(X_test_fp)\n",
    "y_prob_fp = rf_smiles.predict_proba(X_test_fp)[:, 1]\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### 2.4) Evaluate SMILES-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "precision_fp, recall_fp, _ = precision_recall_curve(y_test_fp, y_prob_fp)\n",
    "pr_auc_fp = auc(recall_fp, precision_fp)\n",
    "mcc_fp = matthews_corrcoef(y_test_fp, y_pred_fp)\n",
    "bal_acc_fp = balanced_accuracy_score(y_test_fp, y_pred_fp)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SMILES FINGERPRINT MODEL PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test_fp, y_pred_fp, target_names=[\"Non-binder\", \"Binder\"]))\n",
    "print(f\"PR-AUC: {pr_auc_fp:.3f}\")\n",
    "print(f\"Balanced Accuracy: {bal_acc_fp:.3f}\")\n",
    "print(f\"MCC: {mcc_fp:.3f}\")\n",
    "\n",
    "fpr_fp, tpr_fp, _ = roc_curve(y_test_fp, y_prob_fp)\n",
    "roc_auc_fp = auc(fpr_fp, tpr_fp)\n",
    "print(f\"ROC-AUC: {roc_auc_fp:.3f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp_fp = ConfusionMatrixDisplay.from_predictions(y_test_fp, y_pred_fp)\n",
    "plt.title(\"Confusion Matrix — SMILES Fingerprints Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509350f",
   "metadata": {},
   "source": [
    "### 2.4.1) 100-Fold Stability Check\n",
    "\n",
    "To understand how stable the SMILES fingerprint model is, we repeat the stratified train/test split 100 times (5 folds × 20 repeats) and summarize the distribution of key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
    "cv_metrics = []\n",
    "\n",
    "n_folds = cv.get_n_splits(X_fp, y_fp)\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_fp, y_fp), start=1):\n",
    "    X_train_cv, X_test_cv = X_fp[train_idx], X_fp[test_idx]\n",
    "    y_train_cv, y_test_cv = y_fp[train_idx], y_fp[test_idx]\n",
    "\n",
    "    rf_cv = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42 + fold_idx,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_cv.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    y_pred_cv = rf_cv.predict(X_test_cv)\n",
    "    y_prob_cv = rf_cv.predict_proba(X_test_cv)[:, 1]\n",
    "\n",
    "    precision_cv, recall_cv, _ = precision_recall_curve(y_test_cv, y_prob_cv)\n",
    "    pr_auc_cv = auc(recall_cv, precision_cv)\n",
    "    fpr_cv, tpr_cv, _ = roc_curve(y_test_cv, y_prob_cv)\n",
    "    roc_auc_cv = auc(fpr_cv, tpr_cv)\n",
    "\n",
    "    cv_metrics.append({\n",
    "        \"PR-AUC\": pr_auc_cv,\n",
    "        \"ROC-AUC\": roc_auc_cv,\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_test_cv, y_pred_cv),\n",
    "        \"MCC\": matthews_corrcoef(y_test_cv, y_pred_cv),\n",
    "        \"Accuracy\": accuracy_score(y_test_cv, y_pred_cv)\n",
    "    })\n",
    "\n",
    "cv_metrics_df = pd.DataFrame(cv_metrics)\n",
    "cv_summary = cv_metrics_df.agg(['mean', 'std']).T.rename(columns={'mean': 'Mean', 'std': 'Std'})\n",
    "cv_summary.index.name = 'Metric'\n",
    "\n",
    "print(f\"Evaluated {len(cv_metrics_df)} folds across {n_folds} stratified splits\")\n",
    "display(cv_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5db4b4",
   "metadata": {},
   "source": [
    "### 2.4.2) Compare Multiple Classifiers\n",
    "\n",
    "Random Forest has been our default choice, but it's helpful to benchmark other algorithms on the same SMILES fingerprints. Below we train several off-the-shelf classifiers on the existing train/test split and summarize their metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"RandomForest (300 trees)\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"ExtraTrees (400 trees)\": ExtraTreesClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"LogisticRegression (L2)\": LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        solver=\"saga\",\n",
    "        penalty=\"l2\",\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\"\n",
    "    ),\n",
    "    \"GaussianNB\": GaussianNB()\n",
    "}\n",
    "\n",
    "comparison_rows = []\n",
    "for name, clf in classifiers.items():\n",
    "    start = perf_counter()\n",
    "    clf.fit(X_train_fp, y_train_fp)\n",
    "    fit_time = perf_counter() - start\n",
    "\n",
    "    y_pred = clf.predict(X_test_fp)\n",
    "\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        y_score = clf.predict_proba(X_test_fp)[:, 1]\n",
    "    elif hasattr(clf, \"decision_function\"):\n",
    "        y_score = clf.decision_function(X_test_fp)\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    precision_tmp, recall_tmp, _ = precision_recall_curve(y_test_fp, y_score)\n",
    "    pr_auc_tmp = auc(recall_tmp, precision_tmp)\n",
    "    fpr_tmp, tpr_tmp, _ = roc_curve(y_test_fp, y_score)\n",
    "    roc_auc_tmp = auc(fpr_tmp, tpr_tmp)\n",
    "\n",
    "    comparison_rows.append({\n",
    "        \"Model\": name,\n",
    "        \"PR-AUC\": pr_auc_tmp,\n",
    "        \"ROC-AUC\": roc_auc_tmp,\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_test_fp, y_pred),\n",
    "        \"Accuracy\": accuracy_score(y_test_fp, y_pred),\n",
    "        \"MCC\": matthews_corrcoef(y_test_fp, y_pred),\n",
    "        \"Train Time (s)\": fit_time\n",
    "    })\n",
    "\n",
    "comparison_df = (pd.DataFrame(comparison_rows)\n",
    "                 .set_index(\"Model\")\n",
    "                 .sort_values(\"PR-AUC\", ascending=False))\n",
    "\n",
    "print(\"Classifier comparison on the same SMILES fingerprint split:\")\n",
    "formatter = {\n",
    "    \"PR-AUC\": \"{:.3f}\",\n",
    "    \"ROC-AUC\": \"{:.3f}\",\n",
    "    \"Balanced Accuracy\": \"{:.3f}\",\n",
    "    \"Accuracy\": \"{:.3f}\",\n",
    "    \"MCC\": \"{:.3f}\",\n",
    "    \"Train Time (s)\": \"{:.2f}\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    display(comparison_df.style.format(formatter))\n",
    "except Exception as exc:\n",
    "    print(\"NOTE: Styled display requires jinja2 (and pandas Styler). Showing plain table instead.\")\n",
    "    print(f\"Reason: {exc}\")\n",
    "    display(comparison_df.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14830c4f",
   "metadata": {},
   "source": [
    "## Binary PSO-based feature selection\n",
    "We apply a binary particle swarm optimizer (BPSO) on the fingerprint space to keep only the most informative bits before model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BPSOFeatureSelector:\n",
    "    \"\"\"Binary Particle Swarm Optimization wrapper for feature selection.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        n_particles=20,\n",
    "        n_iterations=25,\n",
    "        inertia=0.729,\n",
    "        cognitive=1.49445,\n",
    "        social=1.49445,\n",
    "        cv=3,\n",
    "        max_features=512,\n",
    "        min_features=1,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        self.estimator = estimator\n",
    "        self.n_particles = n_particles\n",
    "        self.n_iterations = n_iterations\n",
    "        self.inertia = inertia\n",
    "        self.cognitive = cognitive\n",
    "        self.social = social\n",
    "        self.cv = cv\n",
    "        self.max_features = max_features\n",
    "        self.min_features = min_features\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _ensure_valid_mask(self, mask, rng):\n",
    "        if not mask.any():\n",
    "            mask[rng.integers(0, mask.size)] = True\n",
    "        if self.max_features is not None and mask.sum() > self.max_features:\n",
    "            drop = rng.choice(np.where(mask)[0], size=mask.sum() - self.max_features, replace=False)\n",
    "            mask[drop] = False\n",
    "        if self.min_features and mask.sum() < self.min_features:\n",
    "            available = np.where(~mask)[0]\n",
    "            if available.size:\n",
    "                add = rng.choice(available, size=min(self.min_features - mask.sum(), available.size), replace=False)\n",
    "                mask[add] = True\n",
    "        return mask\n",
    "\n",
    "    def _predict_scores(self, estimator, X):\n",
    "        if hasattr(estimator, \"predict_proba\"):\n",
    "            return estimator.predict_proba(X)[:, 1]\n",
    "        if hasattr(estimator, \"decision_function\"):\n",
    "            return estimator.decision_function(X)\n",
    "        return estimator.predict(X)\n",
    "\n",
    "    def _evaluate_mask(self, X, y, mask):\n",
    "        if mask.sum() == 0:\n",
    "            return 0.0\n",
    "        scores = []\n",
    "        for train_idx, valid_idx in self.cv_splits_:\n",
    "            est = clone(self.estimator)\n",
    "            est.fit(X[train_idx][:, mask], y[train_idx])\n",
    "            y_scores = self._predict_scores(est, X[valid_idx][:, mask])\n",
    "            scores.append(average_precision_score(y[valid_idx], y_scores))\n",
    "        return float(np.mean(scores))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        self.cv_splits_ = list(\n",
    "            StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=self.random_state).split(X, y)\n",
    "        )\n",
    "        n_features = X.shape[1]\n",
    "        init_prob = min(0.1, (self.max_features or n_features) / n_features)\n",
    "        positions = rng.random((self.n_particles, n_features)) < init_prob\n",
    "        velocities = rng.standard_normal((self.n_particles, n_features)) * 0.1\n",
    "        for i in range(self.n_particles):\n",
    "            positions[i] = self._ensure_valid_mask(positions[i], rng)\n",
    "        personal_best_positions = positions.copy()\n",
    "        personal_best_scores = np.array([\n",
    "            self._evaluate_mask(X, y, positions[i]) for i in range(self.n_particles)\n",
    "        ])\n",
    "        best_idx = np.argmax(personal_best_scores)\n",
    "        global_best_position = personal_best_positions[best_idx].copy()\n",
    "        global_best_score = personal_best_scores[best_idx]\n",
    "        self.history_ = [\n",
    "            {\n",
    "                \"iteration\": 0,\n",
    "                \"best_score\": float(global_best_score),\n",
    "                \"mean_features\": float(positions.sum(axis=1).mean()),\n",
    "            }\n",
    "        ]\n",
    "        for iteration in range(1, self.n_iterations + 1):\n",
    "            for i in range(self.n_particles):\n",
    "                r1 = rng.random(n_features)\n",
    "                r2 = rng.random(n_features)\n",
    "                personal_best = personal_best_positions[i].astype(float)\n",
    "                position_float = positions[i].astype(float)\n",
    "                global_best = global_best_position.astype(float)\n",
    "                velocities[i] = (\n",
    "                    self.inertia * velocities[i]\n",
    "                    + self.cognitive * r1 * (personal_best - position_float)\n",
    "                    + self.social * r2 * (global_best - position_float)\n",
    "                )\n",
    "                probs = 1.0 / (1.0 + np.exp(-velocities[i]))\n",
    "                new_position = rng.random(n_features) < probs\n",
    "                new_position = self._ensure_valid_mask(new_position, rng)\n",
    "                positions[i] = new_position\n",
    "                score = self._evaluate_mask(X, y, new_position)\n",
    "                if score > personal_best_scores[i]:\n",
    "                    personal_best_scores[i] = score\n",
    "                    personal_best_positions[i] = new_position.copy()\n",
    "                    if score > global_best_score:\n",
    "                        global_best_score = score\n",
    "                        global_best_position = new_position.copy()\n",
    "            self.history_.append(\n",
    "                {\n",
    "                    \"iteration\": iteration,\n",
    "                    \"best_score\": float(global_best_score),\n",
    "                    \"mean_features\": float(positions.sum(axis=1).mean()),\n",
    "                }\n",
    "            )\n",
    "        self.support_ = global_best_position.astype(bool)\n",
    "        self.best_score_ = float(global_best_score)\n",
    "        self.selected_features_ = np.where(self.support_)[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not hasattr(self, \"support_\"):\n",
    "            raise RuntimeError(\"The selector is not fitted yet.\")\n",
    "        return np.asarray(X)[:, self.support_]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f4ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run BPSO on the training fingerprints only\n",
    "bpso_base_estimator = LogisticRegression(\n",
    "    max_iter=600,\n",
    "    solver=\"saga\",\n",
    "    penalty=\"l2\",\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "bpso_selector = BPSOFeatureSelector(\n",
    "    estimator=bpso_base_estimator,\n",
    "    n_particles=18,\n",
    "    n_iterations=20,\n",
    "    cv=3,\n",
    "    max_features=512,\n",
    "    min_features=16,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "bpso_selector.fit(X_train_fp, y_train_fp)\n",
    "selected_mask = bpso_selector.support_\n",
    "X_train_bpso = X_train_fp[:, selected_mask]\n",
    "X_test_bpso = X_test_fp[:, selected_mask]\n",
    "\n",
    "print(f\"BPSO selected {selected_mask.sum()} / {X_train_fp.shape[1]} features\")\n",
    "print(f\"Best cross-validated average precision: {bpso_selector.best_score_:.4f}\")\n",
    "\n",
    "bpso_history = pd.DataFrame(bpso_selector.history_)\n",
    "display(bpso_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a Random Forest on the BPSO-selected features\n",
    "rf_bpso = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf_bpso.fit(X_train_bpso, y_train_fp)\n",
    "\n",
    "y_pred_bpso = rf_bpso.predict(X_test_bpso)\n",
    "y_prob_bpso = rf_bpso.predict_proba(X_test_bpso)[:, 1]\n",
    "\n",
    "precision_bpso, recall_bpso, _ = precision_recall_curve(y_test_fp, y_prob_bpso)\n",
    "pr_auc_bpso = auc(recall_bpso, precision_bpso)\n",
    "mcc_bpso = matthews_corrcoef(y_test_fp, y_pred_bpso)\n",
    "bal_acc_bpso = balanced_accuracy_score(y_test_fp, y_pred_bpso)\n",
    "roc_auc_bpso = auc(*roc_curve(y_test_fp, y_prob_bpso)[:2])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RANDOM FOREST WITH BPSO-SELECTED FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test_fp, y_pred_bpso, target_names=[\"Non-binder\", \"Binder\"]))\n",
    "print(f\"PR-AUC: {pr_auc_bpso:.3f}\")\n",
    "print(f\"Balanced Accuracy: {bal_acc_bpso:.3f}\")\n",
    "print(f\"MCC: {mcc_bpso:.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_bpso:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wyaktan91ki",
   "metadata": {},
   "source": [
    "## 3) Optimizing SMILES Fingerprints\n",
    "\n",
    "The physicochemical features currently outperform SMILES fingerprints. Let's optimize the SMILES representation by testing different fingerprint types and configurations (NOT Random Forest hyperparameters - we keep RF at default settings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7qsug32kt5c",
   "metadata": {},
   "source": [
    "### 3.1) Fingerprint Comparison\n",
    "\n",
    "Let's systematically test different fingerprint types and configurations to find the optimal representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nf09vmrbglm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetRDKitFPGenerator\n",
    "\n",
    "def smiles_to_maccs(smiles):\n",
    "    \"\"\"Convert SMILES to MACCS keys (167 bits).\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "        return np.array(fp)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def smiles_to_rdkit_fp(smiles, n_bits=2048):\n",
    "    \"\"\"Convert SMILES to RDKit fingerprint.\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        rdkit_gen = GetRDKitFPGenerator(fpSize=n_bits)\n",
    "        fp = rdkit_gen.GetFingerprint(mol)\n",
    "        return np.array(fp)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Test different fingerprint types\n",
    "fingerprint_types = {\n",
    "    'Morgan (radius=2, 2048 bits)': lambda s: smiles_to_fingerprint(s, radius=2, n_bits=2048),\n",
    "    'Morgan (radius=3, 2048 bits)': lambda s: smiles_to_fingerprint(s, radius=3, n_bits=2048),\n",
    "    'Morgan (radius=2, 4096 bits)': lambda s: smiles_to_fingerprint(s, radius=2, n_bits=4096),\n",
    "    'MACCS Keys (167 bits)': smiles_to_maccs,\n",
    "    'RDKit FP (2048 bits)': smiles_to_rdkit_fp\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for fp_name, fp_func in fingerprint_types.items():\n",
    "    print(f\"\\nTesting {fp_name}...\")\n",
    "    \n",
    "    # Generate fingerprints\n",
    "    fps = []\n",
    "    valid_idx = []\n",
    "    for idx, smiles in enumerate(df_smiles['Smiles']):\n",
    "        fp = fp_func(smiles)\n",
    "        if fp is not None:\n",
    "            fps.append(fp)\n",
    "            valid_idx.append(idx)\n",
    "    \n",
    "    X_fps = np.array(fps)\n",
    "    y_fps = df_smiles.iloc[valid_idx]['Binder'].values\n",
    "    \n",
    "    # Train/test split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X_fps, y_fps, test_size=0.25, random_state=42, stratify=y_fps\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    rf_temp = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=20\n",
    "    )\n",
    "    rf_temp.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_temp = rf_temp.predict(X_te)\n",
    "    y_prob_temp = rf_temp.predict_proba(X_te)[:, 1]\n",
    "    \n",
    "    prec_temp, rec_temp, _ = precision_recall_curve(y_te, y_prob_temp)\n",
    "    pr_auc_temp = auc(rec_temp, prec_temp)\n",
    "    mcc_temp = matthews_corrcoef(y_te, y_pred_temp)\n",
    "    acc_temp = (y_pred_temp == y_te).mean()\n",
    "    \n",
    "    results[fp_name] = {\n",
    "        'PR-AUC': pr_auc_temp,\n",
    "        'MCC': mcc_temp,\n",
    "        'Accuracy': acc_temp,\n",
    "        'Shape': X_fps.shape\n",
    "    }\n",
    "    \n",
    "    print(f\"  Shape: {X_fps.shape}\")\n",
    "    print(f\"  PR-AUC: {pr_auc_temp:.5f}, MCC: {mcc_temp:.5f}, Accuracy: {acc_temp:.6f}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINGERPRINT COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "comparison_fp = pd.DataFrame(results).T\n",
    "print(comparison_fp.to_string())\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify best fingerprint\n",
    "best_fp = comparison_fp['PR-AUC'].idxmax()\n",
    "print(f\"\\n⭐ BEST PERFORMER: {best_fp}\")\n",
    "print(f\"   PR-AUC: {comparison_fp.loc[best_fp, 'PR-AUC']:.5f}\")\n",
    "print(f\"   MCC: {comparison_fp.loc[best_fp, 'MCC']:.5f}\")\n",
    "print(f\"   Accuracy: {comparison_fp.loc[best_fp, 'Accuracy']:.6f}\")\n",
    "print(\"\\n✓ Morgan fingerprints with 4096 bits provide the best performance!\")\n",
    "print(\"  This configuration captures more structural detail than 2048 bits.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
